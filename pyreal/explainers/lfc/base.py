from abc import ABC

import numpy as np

from pyreal.explainers import ExplainerBase
from pyreal.transformers import NarrativeTransformer


class LocalFeatureContributionsBase(ExplainerBase, ABC):
    """
    Base class for LocalFeatureContributions explainer objects. Abstract class

    A LocalFeatureContributionsBase object explains a machine learning prediction by assigning an
    importance or contribution score to every feature. LocalFeatureContributionBase objects explain
    by taking an instance and returning one number per feature, per instance.

    Args:
        model (string filepath or model object):
           Filepath to the pickled model to explain, or model object with .predict() function
        x_train_orig (dataframe of shape (n_instances, x_orig_feature_count)):
           The training set for the explainer
        **kwargs: see base Explainer args
    """

    def __init__(self, model, x_train_orig=None, **kwargs):
        self.llm_training_data = None
        super(LocalFeatureContributionsBase, self).__init__(model, x_train_orig, **kwargs)

    def evaluate_variation(self, with_fit=False, explanations=None, n_iterations=20, n_rows=10):
        """
        Evaluate the variation of the explanations generated by this Explainer.
        A variation of 0 means this explainer is expected to generate the exact same explanation
        given the same model and input. Variation is always non-negative, and can be arbitrarily
        high.

        Args:
            with_fit (Boolean):
                If True, evaluate the variation in explanations including the fit (fit each time
                before running). If False, evaluate the variation in explanations of a pre-fit
                Explainer.
            explanations (None or List of DataFrames of shape (n_instances, n_features)):
                If provided, run the variation check on the precomputed list of explanations
                instead of generating
            n_iterations (int):
                Number of explanations to generate to evaluation variation
            n_rows (int):
                Number of rows of dataset to generate explanations on

        Returns:
            float
                The variation of this Explainer's explanations
        """
        if explanations is None:
            explanations = []
            for i in range(n_iterations - 1):
                if with_fit:
                    self.fit()
                explanations.append(
                    self.produce(self.x_train_orig_subset.iloc[0:n_rows]).get().to_numpy()
                )

        return np.max(np.var(explanations, axis=0))

    def produce_narrative_explanation(
        self,
        x_orig,
        num_features=5,
        llm_model="gpt3.5",
        detail_level="high",
        context_description="",
        max_tokens=200,
        temperature=0.5,
        openai_client=None,
    ):
        """
        Produces an explanation in narrative (natural-language) form.
        Args:
            x_orig (DataFrame of shape (n_instances, n_features):
                Input to explain
            num_features (int):
                Number of features to include in the explanation. If None, all features will be
                included
            llm_model (string):
                One of ["gpt3.5", "gpt4"]. LLM model to use to generate the explanation.
                GPT4 may provide better results, but is more expensive.
            detail_level (string):
                One of ["high", "low"]. Level of detail to include in the explanation.
                High detail should include precise contribution values. Low detail
                will include only basic information about features used.
            context_description (string):
                Description of the model's prediction task, in sentence format. This will be
                passed to the LLM and may help produce more accurate explanations.
                For example: "The model predicts the price of houses."
            max_tokens (int):
                Maximum number of tokens to use in the explanation
            temperature (float):
                LLM Temperature to use. Values closer to 1 will produce more creative values.
                Values closer to 0 will produce more consistent or conservative explanations.
            openai_client (OpenAI API client):
                OpenAI API client, with API key set. If None, the API key must be provided to the
                explainer at initialization.

        Returns:
            list of strings of length n_instances
                Narrative version of feature contribution explanation, one item per instance
        """
        if openai_client is None:
            if self.openai_client is None:
                raise ValueError("OpenAI API key or client must be provided to produce narrative")
            openai_client = self.openai_client

        narrative_transformer = NarrativeTransformer(
            openai_client=openai_client,
            num_features=num_features,
            llm_model=llm_model,
            detail_level=detail_level,
            context_description=context_description,
            max_tokens=max_tokens,
            temperature=temperature,
            training_examples={"feature_contributions": self.llm_training_data},
        )
        self.transformers.append(narrative_transformer)
        result = self.produce(x_orig)
        self.transformers.pop()
        return result

    def train_llm(
        self, x_train=None, live=True, provide_examples=False, num_inputs=5, num_features=3
    ):
        """
        Run the training process for the LLM model used to generate narrative feature
        contribution explanations.

        Args:
            x_train (DataFrame of shape (n_instances, n_features)):
                Training set to take sample inputs from. If None, the training set must be provided
                to the explainer at initialization.
            live (Boolean):
                If True, run the training process through CLI input/outputs. If False,
                this function will generate a shell training file that will need to be filled out
                and added to the RealApp manually. Currently only live training is supported.
            provide_examples (Boolean):
                If True, generate a base example of explanations at each step. This may make
                the process faster, but will incur costs to your OpenAI API account.
            num_inputs (int):
                Number of inputs to request.
            num_features (int):
                Number of features to include per explanation. If None, all features will be
                included

        Returns:
            list of (explanation, narrative) pairs
                The generated training data
        """
        if not live:
            raise NotImplementedError("Non-interactive training not yet implemented")
        if provide_examples and self.openai_client is None:
            raise ValueError(
                "OpenAI API key or client must be provided to provide examples during training"
            )
        x_train = self._get_x_train_orig(x_train)
        if num_inputs > len(x_train):
            print(
                "Warning: number of inputs in x_train is less than num_inputs, using all available"
                " inputs"
            )
        else:
            x_train = x_train.sample(num_inputs)
        explanation = self.produce(x_train)
        parsed_explanations = NarrativeTransformer.parse_feature_contribution_explanation_for_llm(
            explanation, num_features=num_features
        )
        narratives = []
        print("For each of the following inputs, please provide an appropriate narrative version.")
        for i in range(num_inputs):
            instruction = ""
            parsed_explanation_formatted = parsed_explanations[i].replace("), ", "),\n")
            instruction += (
                f"Input {i+1} (feature, value, contribution):\n{parsed_explanation_formatted}\n"
            )
            if provide_examples:
                example = (
                    NarrativeTransformer(
                        openai_client=self.openai_client, num_features=num_features
                    )
                    .transform_explanation_feature_contribution(explanation[i])
                    .get()[0]
                )
                instruction += f"Example: {example}\n"
                instruction += "Narrative explanation ('k' to keep example, 'q' to quit): "
                narrative = input(instruction)
                if narrative.lower() == "k":
                    narrative = example
            else:
                instruction += "Narrative explanation ('q' to quit): "
                narrative = input(instruction)
            if narrative.lower() == "q":
                break
            narratives.append((parsed_explanations[i], narrative))
        if len(narratives) > 0 and input("Save training data? (y/n): ").lower() == "y":
            self.llm_training_data = narratives
            print(f"Training complete. Training data: {narratives}")
        else:
            print("Training data not saved.")
        return narratives

    def clear_llm_training_data(self):
        """
        Remove few-shot training examples from the explainer
        """
        self.llm_training_data = None

    def set_llm_training_data(self, training_data):
        """
        Manually set llm training data

        Args:
            training_data (list of (explanation, narrative) pairs):
                Training examples to use for few-shot learning. If provided, the LLM will be
                trained on these examples before generating the explanation.
        """
        self.llm_training_data = training_data
