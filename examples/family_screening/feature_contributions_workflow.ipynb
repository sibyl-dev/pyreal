{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load in the information Sibyl needs. This includes the model, the dataset, and the hand-written mappings object that allows for conversions to a categorical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 460) (460,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Columns (222) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "sys.path.insert(1, '../../../sibyl')\n",
    "\n",
    "directory = \"data/\"\n",
    "dataset_filename = os.path.join(directory, \"Model_Dataset_Version_01_01.csv\")\n",
    "features_filename = os.path.join(directory, \"Design_Specification_DOUGLAS_v1.4.csv\")\n",
    "model_filename = os.path.join(directory, \"weights_model_feb2019.csv\")\n",
    "feature_mappings_filename = os.path.join(directory, \"mappings.csv\")\n",
    "\n",
    "# LOAD IN THE BASE MODEL\n",
    "\n",
    "from sibyl.utils import model_utils, transformer\n",
    "importlib.reload(model_utils)\n",
    "importlib.reload(transformer)\n",
    "\n",
    "weights_df = pd.read_csv(model_filename)\n",
    "weights = weights_df[\"weight\"]\n",
    "model_features = weights_df[\"name\"][1:]\n",
    "model = model_utils.load_model_from_weights(weights, model_type=\"linear_regression\")\n",
    "feature_select = transformer.FeatureSelectTransformer(model_features)\n",
    "\n",
    "# LOAD IN THE MAPPINGS OBJECT\n",
    "\n",
    "from sibyl.utils import mappings\n",
    "importlib.reload(mappings)\n",
    "\n",
    "mappings = mappings.Mappings.generate_mappings(dataframe=pd.read_csv(feature_mappings_filename))\n",
    "\n",
    "# LOAD IN THE DATASET\n",
    "\n",
    "x_orig = pd.read_csv(dataset_filename)\n",
    "x_orig = dataset[model_features].astype(\"float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now have everything we need to set up a FeatureContributionExplainer object, and begin using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sibyl.explainers.local_feature_explanation as lfe\n",
    "importlib.reload(lfe)\n",
    "\n",
    "lce = lfe.FeatureContributionExplainer(model, x_orig, y_orig=None, \n",
    "                                       e_transforms=feature_select, m_transforms=None,\n",
    "                                       e_algorithm=\"shap\", fit_on_init=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now fit the contribution explainer, and time it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken to fit full dataset: 0.113702 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "lce.fit_contributions()\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Total time taken to fit full dataset: %f seconds\" % (end_time-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can get contributions, and time the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time time taken to get contributions on 1000 items: 0.007009 seconds\n"
     ]
    }
   ],
   "source": [
    "d = 1000\n",
    "x_orig_daily = dataset.sample(d)\n",
    "\n",
    "start_time = time.time()\n",
    "contributions = lce.get_contributions(x_orig_daily) \n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Time time taken to get contributions on %s items: %f seconds\" % (d, end_time-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can take a look at the contributions found, and see if they make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PRI_CBMS_FOCUS_CD', 'PRI_CBMS_FOCUS_CH', 'PRI_CBMS_FOCUS_CP',\n",
      "       'PRI_CBMS_FOCUS_CW', 'PRI_CBMS_FOCUS_DF', 'PRI_CBMS_FOCUS_EX',\n",
      "       'PRI_CBMS_FOCUS_FM', 'PRI_CBMS_FOCUS_FP', 'PRI_CBMS_FOCUS_FS',\n",
      "       'PRI_CBMS_FOCUS_FT',\n",
      "       ...\n",
      "       'PRI_OTHA_REF_NEGLECT_COUNT', 'PRI_OTHA_REF_EMOTIONAL_COUNT',\n",
      "       'PRI_OTHA_REF_PHYSICAL_COUNT', 'PRI_OTHA_REF_DRUG_COUNT',\n",
      "       'PRI_OTHA_REF_SEXUAL_COUNT', 'PRI_OTHA_REF_OTHER_COUNT',\n",
      "       'PRI_OTHA_REF_DOMESTIC_VIOLENCE_COUNT', 'PRI_OTHA_CYF_ACTIVE',\n",
      "       'PRI_OTHA_JUVENILE_JUSTICE', 'PRI_OTHA_COURT_ACTIVE'],\n",
      "      dtype='object', length=358)\n",
      "Time taken to encode full dataset: 0.781941 seconds\n"
     ]
    }
   ],
   "source": [
    "# time taken to convert to categorical\n",
    "from sibyl.utils import transformer\n",
    "importlib.reload(transformer)\n",
    "import time\n",
    "\n",
    "cat_transformer = transformer.MappingsDecoderTransformer(mappings)\n",
    "\n",
    "start_time = time.time()\n",
    "transformed = cat_transformer.transform(dataset)\n",
    "end_time = time.time()\n",
    "print(transformed.columns)\n",
    "\n",
    "print(\"Time taken to encode full dataset: %f seconds\" % (end_time-start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
