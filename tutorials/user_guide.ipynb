{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# User Guide Follow-Along Code\n",
    "\n",
    "This tutorial contains all the code used in the [Pyreal User Guides](https://dtail.gitbook.io/pyreal/user-guides/data-preparation-and-modelling). We recommend following along with the text there.\n",
    "\n",
    "This tutorial uses a smaller version of the Ames Housing Dataset [1], with 8 key features selected. In this guide, we will train an ML model that predicts the sale price of houses based on these features. \n",
    "\n",
    "[1] De Cock, D. (2011). Ames, Iowa: Alternative to the Boston Housing Data as an End of Semester Regression Project. Journal of Statistics Education, 19(3). https://doi.org/10.1080/10691898.2011.11889627"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e47dbc3ca3ca5491"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preparation and Modelling\n",
    "## Training and Input Data\n",
    "\n",
    "Pyreal expects data in the format of Pandas DataFrames. Each row refers to one data instance (a person, place, thing, or entity), and each column refers to a feature, or piece of information about that instance. Column headers are the names of feature. Each instance may optionally have an instance ID, which can either be stored as the DataFrame's indices (row IDs) or as a separate column.\n",
    "\n",
    "There are three categories of data relevant to ML decision-making: training data, testing data, and input data.\n",
    "The training data is used to train the ML model and explainers. The testing data is used to evaluate the performance of the ML model (ie., how accurately it makes predictions). The input data is the data that you actively wish to get predictions on and understand better. \n",
    "For training and test data, we will usually have the ground truth values (the \"correct\" answer for the value your model tries to predict, often referred to as y-values) for all rows of data. \n",
    "For example, if we are trying to predict house prices, you would have additional information about the price of houses in your training/testing datasets. Pyreal expects these target values as pandas Series.\n",
    "\n",
    "In the next cell we load in the training data from Pyreal's `sample_applicatons` module, split it into train and test sets using sklearn, and then inspect it."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7199f948c5d5624"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pyreal.sample_applications import ames_housing_small\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x, y = ames_housing_small.load_data(include_targets=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "x_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-03-20T17:38:52.743175900Z"
    }
   },
   "id": "26e2eb02bc958536",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The training data is used to train the ML model and explainers. The input data is the data that you actively wish to get predictions on and understand better. The main difference between these two types is data is that you usually will have the ground truth values (the \"correct\" answer for the value your model tries to predict) for your training data but not your input data.\n",
    "\n",
    "In the cell below, we inspect our ground-truth information for our training data, `y_train`, stored in a pandas Series."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b96fd48acd8dc9a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the cell below, we load in and inspect out input data. For this data we have no ground truth values."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95aee1d4f9e9f624"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x_input = ames_housing_small.load_input_data()\n",
    "x_input"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b7e2ad14e7741b9",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformers\n",
    "\n",
    "Many ML models either require data to be in a specific format, or preform significantly better when data is a specific format. \n",
    "For example, many models require all data to be numeric, cannot handle missing data, or expect all features to be on similar numeric scales. But this is rarely the case in real-world applications, so we need to perform feature engineering using data transformers.\n",
    "\n",
    "In the cell below, we initialize all the transformers we will need to make predictions with our model. See the [Pyreal User Guide](https://dtail.gitbook.io/pyreal/user-guides/data-preparation-and-modelling/transformers) for details.\n",
    "\n",
    "We then fit the transformers to our training data, and inspect the resulting transformed data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b634e22220e9e88"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pyreal.transformers import OneHotEncoder, MultiTypeImputer, StandardScaler, fit_transformers\n",
    "\n",
    "oh_encoder = OneHotEncoder(columns=[\"Neighborhood\", \"Material\"], handle_unknown=\"ignore\")\n",
    "imputer = MultiTypeImputer()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "transformers = [oh_encoder, imputer, scaler]\n",
    "fit_transformers(transformers, x_train).head()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "da666fc9d0b86df6",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelling\n",
    "\n",
    "We can now transform our training and testing data, and initialize, train, and evaluate our ML model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6249bff7ce879d4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pyreal.transformers import run_transformers\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "x_train_model = run_transformers(transformers, x_train)\n",
    "x_test_model = run_transformers(transformers, x_test)\n",
    "\n",
    "model = LGBMRegressor().fit(x_train_model, y_train)\n",
    "\n",
    "model.score(x_test_model, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "834ff0a3692c0d27",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating New Applications (RealApps)\n",
    "\n",
    "We can now combine the components we have created to create a new application, using the RealApp object. \n",
    "We set the ID column to \"House ID\", which is the column we use to ID our input data. We also pass in\n",
    "a feature description dictionary, which converts our column names to more useful descriptions. Finally, \n",
    "we set a pred format functions to format the model predictions to dollar amounts."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65015526ebf2b06e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pyreal import RealApp\n",
    "\n",
    "feature_descriptions = {'LotArea': 'Lot size in square feet', \n",
    "                        'Neighborhood': 'Neighborhood', \n",
    "                        'OverallQuality': 'Overall quality of the house finishing and materials (1-10)', \n",
    "                        'YearBuilt': 'Original construction date', \n",
    "                        'Material': 'Exterior material of house', \n",
    "                        'BasementSize': 'Total basement area in square feet', \n",
    "                        'CentralAir': 'Central air conditioning', \n",
    "                        'HouseSize': 'Total above ground living area in square feet'}\n",
    "\n",
    "realapp = RealApp(model, \n",
    "                  X_train_orig=x_train, \n",
    "                  y_train=y_train, \n",
    "                  transformers=transformers,\n",
    "                  id_column=\"House ID\",\n",
    "                  feature_descriptions=feature_descriptions,\n",
    "                  pred_format_func=lambda x: f\"${x:,.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "d0d2aed2a921365",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  Using Applications (RealApps)\n",
    "\n",
    "Having created your RealApp, you can now use it to make predictions with and understand your ML model.\n",
    "\n",
    "## Predictions\n",
    "The most basic yet important functionality of an ML model is making predictions. For this, you can use the .predict() function. This function takes data in the original format, and then runs all transformers needed to prepare your input data for the model.\n",
    "\n",
    "The output of the predict function is a dictionary with keys determined by the ID column. If not ID column is provided, the output is indexed by input index (row names).\n",
    "This allows you to access predictions for specific instances by ID."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ec190e53e47429f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "predictions = realapp.predict(x_input)\n",
    "\n",
    "print(f\"Predicted price for House 101: {predictions['House 101']}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ff77d6baf87bc246",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Explanations\n",
    "Sometimes you may want more information about how an ML model came up with its prediction on an input. Or, you may have questions about the ML model in general.\n",
    "\n",
    "For our example application of predicting house prices based on information about houses, you may have questions like:\n",
    "1. What information about the house (or features) contributed to the prediction of $137,000?\n",
    "2. Have we seen houses in the past similar to this one, and what were their prices?\n",
    "3. What features, in general, does the model consider most important for predicting house prices?\n",
    "4. How does the model use the \"house size\" feature? Are bigger houses always predicted to be more expensive?\n",
    "\n",
    "### What features contributed to the model prediction?\n",
    "To get a list of how much each feature in your input data contributed to the model's prediction, you can use the .produce_feature_contributions(x_orig) function.\n",
    "\n",
    "Feature contribution outputs from RealApps are indexed by row ids, found in the column labelled by the optional id_column parameter to RealApps, or by the index (row labels) of the input data if no id column is provided. \n",
    "This allows us to access the explanation for a given house by ID:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74d62f1687c832b0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "contribution_scores = realapp.produce_feature_contributions(x_input)\n",
    "contribution_scores[\"House 101\"]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ae411592de8367a7",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you are only interested in the most contributing features (either positively, negatively, or by absolute value), you can using the num_features and select_by parameters. Alternatively, you can extract the top contributing features from an already-generated explanation using the get_top_contributors function."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c299a95b4b3fc3b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pyreal.utils import get_top_contributors\n",
    "\n",
    "# select_by is one of: \"absolute\", \"min\", \"max\"\n",
    "top_contributions_for_house_101 = get_top_contributors(contribution_scores[\"House 101\"], \n",
    "                                                       num_features=5, \n",
    "                                                       select_by=\"absolute\")\n",
    "\n",
    "# Or...\n",
    "top_5_contribution_scores = realapp.produce_feature_contributions(x_input, \n",
    "                                                                  num_features=5,\n",
    "                                                                  select_by=\"absolute\")\n",
    "top_5_contribution_scores[\"House 101\"]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "45ea8ef9556137b0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Which past cases are similar to this one?\n",
    "You can get a list of past cases (rows of data in the training data) that are similar to your input data, as well as the ground-truth target (y) value for those cases, by using the produce_similiar_examples function:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "830610cdf2997bc9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get the three most similar houses from the \n",
    "# training dataset to each house in houses\n",
    "similar_houses = realapp.produce_similar_examples(x_input, \n",
    "                                                  num_examples=3)\n",
    "\n",
    "display(similar_houses[\"House 101\"][\"X\"])\n",
    "display(similar_houses[\"House 101\"][\"y\"])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c98cca91d2c046b3",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### What features does the model consider most important in general?\n",
    "\n",
    "You may be interested in understanding which features the model considers most important in general, without considering a specific input. For this, you can use the produce_feature_importance function, which takes no required inputs:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "924a4ecf91c5d85e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "importance_scores = realapp.produce_feature_importance()\n",
    "\n",
    "# Like with feature contributions, you can return only the most important features\n",
    "#  or extract the most important features using `get_top_contributors`\n",
    "top_5_importance_scores = realapp.produce_feature_importance(num_features=5)\n",
    "top_5_importance_scores"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "8c00bcdfd7994e6a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### How does the model use a specific feature?\n",
    "To understand how the model uses a specific feature, you can generate feature contributions for the full training dataset, and then investigate how the contributions vary for a specific feature by value.\n",
    "To save time generating large numbers of contributions, and get the output in a more usable format for this specific use-case, you can set the format_output parameter to produce functions to False."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2590968b89c557d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "contribution_scores_df = realapp.produce_feature_contributions(x_input, format_output=False)\n",
    "\n",
    "# explanation is now a tuple of (feature contributions, feature values), where\n",
    "#  the column names are feature descriptions and the index are the row ids.\n",
    "\n",
    "contributions, values = contribution_scores_df\n",
    "\n",
    "# You can now investigate a single features contributions with:\n",
    "pd.DataFrame({\"Value of lot size feature\": values[\"Lot size in square feet\"], \n",
    "              \"Contribution of lot size feature\": contributions[\"Lot size in square feet\"]})"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "fe41f580cc714ef8",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualization\n",
    "Pyreal's visualize module includes several functions that take in RealApp output directly to generate explanation plots.\n",
    "\n",
    "The feature bar plot can visualize general feature importance or feature contributions for a single input."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff345510571d4f27"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pyreal.visualize import feature_bar_plot\n",
    "\n",
    "feature_bar_plot(importance_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "9cc31bf48201eefb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "For feature contribution explanations, the feature value is included in parentheses in the y-axis labels."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7d6a5b3169e1744"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "feature_bar_plot(contribution_scores[\"House 101\"])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "53cb5c94eef3b2c2",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Strip plots are an effective way to visualize feature contributions for multiple inputs at a time, to understand the general trends of how the ML model uses features."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdd38e0b2a32c652"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pyreal.visualize import strip_plot\n",
    "\n",
    "training_set_contributions = realapp.produce_feature_contributions(x_train.iloc[:100])\n",
    "strip_plot(training_set_contributions)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "eeee875735e6847f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Scatter plots allow you to investigate how the model uses a specific feature, across the full range of that feature's values:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "718c0b34d728e13"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pyreal.visualize import feature_scatter_plot\n",
    "\n",
    "# Optionally pass in predictions to color the plot by prediction\n",
    "predictions = realapp.predict(x_train.iloc[:100], format=False)\n",
    "\n",
    "feature_scatter_plot(training_set_contributions, \"Total above ground living area in square feet\", predictions=predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "4ee0934993904b5c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "To get a clean table comparing the feature values of an input data row to those of similar examples, you can use the example_table function:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41b514af927a378f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pyreal.visualize import example_table\n",
    "\n",
    "example_table(similar_houses[\"House 101\"])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "53564fdf7431760c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Narrative Explanations (Using LLMs)\n",
    "You may prefer to get explanations in natural-language sentences. For example, instead of a table or graph of feature contributions, you may prefer what we call a *narrative explanation*.\n",
    "\n",
    "To generate narrative explanations accurately, we plug the explanations generated by Pyreal into a large language model (LLM), which automatically converts it into sentence format.\n",
    "Currently, Pyreal requires an OpenAI API key to use its narrative explanation functionality, which will incur a cost. \n",
    "To generate narrative explanations, you can either pass your API key to the RealApp object at initialization or with the `set_openai_client` function, or to the produce function. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b30904648094371d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# You can create your own keys.yml file with the line `openai_api_key: [your key]`\n",
    "#   or manually set openai_api_key below\n",
    "with open(\"keys.yml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    openai_api_key = config[\"openai_api_key\"]\n",
    "\n",
    "realapp.set_openai_client(openai_api_key=openai_api_key)\n",
    "narratives = realapp.produce_narrative_feature_contributions(x_input)\n",
    "\n",
    "narratives[\"House 101\"]"
   ],
   "metadata": {
    "collapsed": false,
    "tags": [
     "raises-exception"
    ],
    "is_executing": true
   },
   "id": "40dc5d39dbdcff59",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can train the LLM on what kinds of explanations you want. This is called few-shot learning. The LLM asks you for some examples of explanations, and then learns from those examples.\n",
    "To run this training, you can use the .train_feature_contribution_llm. This function will show a few feature contributions explanations, and ask you for narrative versions using Python input/output."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed84637a814476cd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set to True to run this cell\n",
    "RUN_TRAINING = False\n",
    "\n",
    "if RUN_TRAINING:\n",
    "    realapp.train_feature_contribution_llm(num_inputs=2, num_features=2)\n",
    "    narratives = realapp.produce_narrative_feature_contributions(x_input)\n",
    "    \n",
    "    # Explanations will now more closely match the examples you provided\n",
    "    display(narratives[\"House 101\"])"
   ],
   "metadata": {
    "collapsed": false,
    "tags": [
     "raises-exception"
    ],
    "is_executing": true
   },
   "id": "87ceb32bae574284",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
