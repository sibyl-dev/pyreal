{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# User Guide Follow-Along Code\n",
    "\n",
    "This tutorial contains all the code used in the [Pyreal User Guides](https://dtail.gitbook.io/pyreal/user-guides/data-preparation-and-modelling). We recommend following along with the text there.\n",
    "\n",
    "This tutorial uses a smaller version of the Ames Housing Dataset [1], with 8 key features selected. In this guide, we will train an ML model that predicts the sale price of houses based on these features. \n",
    "\n",
    "[1] De Cock, D. (2011). Ames, Iowa: Alternative to the Boston Housing Data as an End of Semester Regression Project. Journal of Statistics Education, 19(3). https://doi.org/10.1080/10691898.2011.11889627"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e47dbc3ca3ca5491"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preparation and Modelling\n",
    "## Training and Input Data\n",
    "\n",
    "Pyreal expects data in the format of Pandas DataFrames. Each row refers to one data instance (a person, place, thing, or entity), and each column refers to a feature, or piece of information about that instance. Column headers are the names of feature. Each instance may optionally have an instance ID, which can either be stored as the DataFrame's indices (row IDs) or as a separate column.\n",
    "\n",
    "There are three categories of data relevant to ML decision-making: training data, testing data, and input data.\n",
    "The training data is used to train the ML model and explainers. The testing data is used to evaluate the performance of the ML model (ie., how accurately it makes predictions). The input data is the data that you actively wish to get predictions on and understand better. \n",
    "For training and test data, we will usually have the ground truth values (the \"correct\" answer for the value your model tries to predict, often referred to as y-values) for all rows of data. \n",
    "For example, if we are trying to predict house prices, you would have additional information about the price of houses in your training/testing datasets. Pyreal expects these target values as pandas Series.\n",
    "\n",
    "In the next cell we load in the training data from Pyreal's `sample_applicatons` module, split it into train and test sets using sklearn, and then inspect it."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7199f948c5d5624"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    },
    {
     "data": {
      "text/plain": "      LotArea Neighborhood  OverallQuality  YearBuilt       Material  \\\n7      6120.0    Brookside             7.0     1929.0    Wood Siding   \n1298   9060.0      Edwards             6.0     1939.0  Wood Shingles   \n1345  10261.0      Gilbert             6.0     2000.0   Vinyl Siding   \n474   10208.0   Northridge             7.0     1996.0   Vinyl Siding   \n1303   6000.0    Brookside             6.0     1941.0    Wood Siding   \n\n      BasementSize CentralAir  HouseSize  \n7              NaN       True      854.0  \n1298         560.0       True     1258.0  \n1345         936.0       True     1792.0  \n474         1264.0       True     2344.0  \n1303         735.0       True     1218.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LotArea</th>\n      <th>Neighborhood</th>\n      <th>OverallQuality</th>\n      <th>YearBuilt</th>\n      <th>Material</th>\n      <th>BasementSize</th>\n      <th>CentralAir</th>\n      <th>HouseSize</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>6120.0</td>\n      <td>Brookside</td>\n      <td>7.0</td>\n      <td>1929.0</td>\n      <td>Wood Siding</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>854.0</td>\n    </tr>\n    <tr>\n      <th>1298</th>\n      <td>9060.0</td>\n      <td>Edwards</td>\n      <td>6.0</td>\n      <td>1939.0</td>\n      <td>Wood Shingles</td>\n      <td>560.0</td>\n      <td>True</td>\n      <td>1258.0</td>\n    </tr>\n    <tr>\n      <th>1345</th>\n      <td>10261.0</td>\n      <td>Gilbert</td>\n      <td>6.0</td>\n      <td>2000.0</td>\n      <td>Vinyl Siding</td>\n      <td>936.0</td>\n      <td>True</td>\n      <td>1792.0</td>\n    </tr>\n    <tr>\n      <th>474</th>\n      <td>10208.0</td>\n      <td>Northridge</td>\n      <td>7.0</td>\n      <td>1996.0</td>\n      <td>Vinyl Siding</td>\n      <td>1264.0</td>\n      <td>True</td>\n      <td>2344.0</td>\n    </tr>\n    <tr>\n      <th>1303</th>\n      <td>6000.0</td>\n      <td>Brookside</td>\n      <td>6.0</td>\n      <td>1941.0</td>\n      <td>Wood Siding</td>\n      <td>735.0</td>\n      <td>True</td>\n      <td>1218.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pyreal.sample_applications import ames_housing_small\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x, y = ames_housing_small.load_data(include_targets=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "x_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-19T21:29:19.548278Z",
     "start_time": "2024-07-19T21:29:17.456091Z"
    }
   },
   "id": "26e2eb02bc958536",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "The training data is used to train the ML model and explainers. The input data is the data that you actively wish to get predictions on and understand better. The main difference between these two types is data is that you usually will have the ground truth values (the \"correct\" answer for the value your model tries to predict) for your training data but not your input data.\n",
    "\n",
    "In the cell below, we inspect our ground-truth information for our training data, `y_train`, stored in a pandas Series."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b96fd48acd8dc9a"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-19T21:29:19.564296Z",
     "start_time": "2024-07-19T21:29:19.549277Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "7       132000\n1298    105000\n1345    186500\n474     265000\n1303    131000\nName: SalePrice, dtype: int64"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the cell below, we load in and inspect out input data. For this data we have no ground truth values."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95aee1d4f9e9f624"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "    House ID  LotArea    Neighborhood  OverallQuality  YearBuilt  \\\n0  House 101     9937         Edwards               5       1965   \n1  House 102     8450   College Creek               7       2003   \n2  House 103     9600         Veenker               6       1976   \n3  House 104    11250   College Creek               7       2001   \n4  House 105     9550        Crawford               7       1915   \n5  House 106    14260      Northridge               8       2000   \n6  House 107    14115        Mitchell               5       1993   \n7  House 108    10084        Somerset               8       2004   \n8  House 109    10382  Northwest Ames               7       1973   \n\n       Material  BasementSize  CentralAir  HouseSize  \n0    Hard Board          1256        True       1256  \n1  Vinyl Siding           856        True       1710  \n2  Metal Siding          1262        True       1262  \n3  Vinyl Siding           920        True       1786  \n4   Wood Siding           756        True       1717  \n5  Vinyl Siding          1145        True       2198  \n6  Vinyl Siding           796        True       1362  \n7  Vinyl Siding          1686        True       1694  \n8    Hard Board          1107        True       2090  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>House ID</th>\n      <th>LotArea</th>\n      <th>Neighborhood</th>\n      <th>OverallQuality</th>\n      <th>YearBuilt</th>\n      <th>Material</th>\n      <th>BasementSize</th>\n      <th>CentralAir</th>\n      <th>HouseSize</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>House 101</td>\n      <td>9937</td>\n      <td>Edwards</td>\n      <td>5</td>\n      <td>1965</td>\n      <td>Hard Board</td>\n      <td>1256</td>\n      <td>True</td>\n      <td>1256</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>House 102</td>\n      <td>8450</td>\n      <td>College Creek</td>\n      <td>7</td>\n      <td>2003</td>\n      <td>Vinyl Siding</td>\n      <td>856</td>\n      <td>True</td>\n      <td>1710</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>House 103</td>\n      <td>9600</td>\n      <td>Veenker</td>\n      <td>6</td>\n      <td>1976</td>\n      <td>Metal Siding</td>\n      <td>1262</td>\n      <td>True</td>\n      <td>1262</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>House 104</td>\n      <td>11250</td>\n      <td>College Creek</td>\n      <td>7</td>\n      <td>2001</td>\n      <td>Vinyl Siding</td>\n      <td>920</td>\n      <td>True</td>\n      <td>1786</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>House 105</td>\n      <td>9550</td>\n      <td>Crawford</td>\n      <td>7</td>\n      <td>1915</td>\n      <td>Wood Siding</td>\n      <td>756</td>\n      <td>True</td>\n      <td>1717</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>House 106</td>\n      <td>14260</td>\n      <td>Northridge</td>\n      <td>8</td>\n      <td>2000</td>\n      <td>Vinyl Siding</td>\n      <td>1145</td>\n      <td>True</td>\n      <td>2198</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>House 107</td>\n      <td>14115</td>\n      <td>Mitchell</td>\n      <td>5</td>\n      <td>1993</td>\n      <td>Vinyl Siding</td>\n      <td>796</td>\n      <td>True</td>\n      <td>1362</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>House 108</td>\n      <td>10084</td>\n      <td>Somerset</td>\n      <td>8</td>\n      <td>2004</td>\n      <td>Vinyl Siding</td>\n      <td>1686</td>\n      <td>True</td>\n      <td>1694</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>House 109</td>\n      <td>10382</td>\n      <td>Northwest Ames</td>\n      <td>7</td>\n      <td>1973</td>\n      <td>Hard Board</td>\n      <td>1107</td>\n      <td>True</td>\n      <td>2090</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_input = ames_housing_small.load_input_data()\n",
    "x_input"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-19T21:29:19.580116Z",
     "start_time": "2024-07-19T21:29:19.565725Z"
    }
   },
   "id": "b7e2ad14e7741b9",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformers\n",
    "\n",
    "Many ML models either require data to be in a specific format, or preform significantly better when data is a specific format. \n",
    "For example, many models require all data to be numeric, cannot handle missing data, or expect all features to be on similar numeric scales. But this is rarely the case in real-world applications, so we need to perform feature engineering using data transformers.\n",
    "\n",
    "In the cell below, we initialize all the transformers we will need to make predictions with our model. See the [Pyreal User Guide](https://dtail.gitbook.io/pyreal/user-guides/data-preparation-and-modelling/transformers) for details.\n",
    "\n",
    "We then fit the transformers to our training data, and inspect the resulting transformed data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b634e22220e9e88"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      Neighborhood_Bloomington Heights  Neighborhood_Bluestem  \\\n7                            -0.121686              -0.044151   \n1298                         -0.121686              -0.044151   \n1345                         -0.121686              -0.044151   \n474                          -0.121686              -0.044151   \n1303                         -0.121686              -0.044151   \n\n      Neighborhood_Briardale  Neighborhood_Brookside  \\\n7                   -0.09398                5.035769   \n1298                -0.09398               -0.198579   \n1345                -0.09398               -0.198579   \n474                 -0.09398               -0.198579   \n1303                -0.09398                5.035769   \n\n      Neighborhood_Clear Creek  Neighborhood_College Creek  \\\n7                    -0.137224                   -0.311638   \n1298                 -0.137224                   -0.311638   \n1345                 -0.137224                   -0.311638   \n474                  -0.137224                   -0.311638   \n1303                 -0.137224                   -0.311638   \n\n      Neighborhood_Crawford  Neighborhood_Edwards  Neighborhood_Gilbert  \\\n7                 -0.208937             -0.259803             -0.240027   \n1298              -0.208937              3.849076             -0.240027   \n1345              -0.208937             -0.259803              4.166190   \n474               -0.208937             -0.259803             -0.240027   \n1303              -0.208937             -0.259803             -0.240027   \n\n      Neighborhood_Iowa DOT and Rail Road  ...  Material_Vinyl Siding  \\\n7                               -0.157877  ...              -0.712272   \n1298                            -0.157877  ...              -0.712272   \n1345                            -0.157877  ...               1.403958   \n474                             -0.157877  ...               1.403958   \n1303                            -0.157877  ...              -0.712272   \n\n      Material_Wood Shingles  Material_Wood Siding  Material_nan   LotArea  \\\n7                  -0.137224              2.561020      -0.21146 -0.465693   \n1298                7.287336             -0.390469      -0.21146 -0.146914   \n1345               -0.137224             -0.390469      -0.21146 -0.016692   \n474                -0.137224             -0.390469      -0.21146 -0.022439   \n1303               -0.137224              2.561020      -0.21146 -0.478704   \n\n      OverallQuality  YearBuilt  BasementSize  CentralAir  HouseSize  \n7           0.672959  -1.411294 -5.743309e-16    0.270313  -1.315999  \n1298       -0.075285  -1.073429 -1.241791e+00    0.270313  -0.490803  \n1345       -0.075285   0.987546 -2.920398e-01    0.270313   0.599925  \n474         0.672959   0.852400  5.364665e-01    0.270313   1.727420  \n1303       -0.075285  -1.005856 -7.997526e-01    0.270313  -0.572506  \n\n[5 rows x 45 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Neighborhood_Bloomington Heights</th>\n      <th>Neighborhood_Bluestem</th>\n      <th>Neighborhood_Briardale</th>\n      <th>Neighborhood_Brookside</th>\n      <th>Neighborhood_Clear Creek</th>\n      <th>Neighborhood_College Creek</th>\n      <th>Neighborhood_Crawford</th>\n      <th>Neighborhood_Edwards</th>\n      <th>Neighborhood_Gilbert</th>\n      <th>Neighborhood_Iowa DOT and Rail Road</th>\n      <th>...</th>\n      <th>Material_Vinyl Siding</th>\n      <th>Material_Wood Shingles</th>\n      <th>Material_Wood Siding</th>\n      <th>Material_nan</th>\n      <th>LotArea</th>\n      <th>OverallQuality</th>\n      <th>YearBuilt</th>\n      <th>BasementSize</th>\n      <th>CentralAir</th>\n      <th>HouseSize</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>-0.121686</td>\n      <td>-0.044151</td>\n      <td>-0.09398</td>\n      <td>5.035769</td>\n      <td>-0.137224</td>\n      <td>-0.311638</td>\n      <td>-0.208937</td>\n      <td>-0.259803</td>\n      <td>-0.240027</td>\n      <td>-0.157877</td>\n      <td>...</td>\n      <td>-0.712272</td>\n      <td>-0.137224</td>\n      <td>2.561020</td>\n      <td>-0.21146</td>\n      <td>-0.465693</td>\n      <td>0.672959</td>\n      <td>-1.411294</td>\n      <td>-5.743309e-16</td>\n      <td>0.270313</td>\n      <td>-1.315999</td>\n    </tr>\n    <tr>\n      <th>1298</th>\n      <td>-0.121686</td>\n      <td>-0.044151</td>\n      <td>-0.09398</td>\n      <td>-0.198579</td>\n      <td>-0.137224</td>\n      <td>-0.311638</td>\n      <td>-0.208937</td>\n      <td>3.849076</td>\n      <td>-0.240027</td>\n      <td>-0.157877</td>\n      <td>...</td>\n      <td>-0.712272</td>\n      <td>7.287336</td>\n      <td>-0.390469</td>\n      <td>-0.21146</td>\n      <td>-0.146914</td>\n      <td>-0.075285</td>\n      <td>-1.073429</td>\n      <td>-1.241791e+00</td>\n      <td>0.270313</td>\n      <td>-0.490803</td>\n    </tr>\n    <tr>\n      <th>1345</th>\n      <td>-0.121686</td>\n      <td>-0.044151</td>\n      <td>-0.09398</td>\n      <td>-0.198579</td>\n      <td>-0.137224</td>\n      <td>-0.311638</td>\n      <td>-0.208937</td>\n      <td>-0.259803</td>\n      <td>4.166190</td>\n      <td>-0.157877</td>\n      <td>...</td>\n      <td>1.403958</td>\n      <td>-0.137224</td>\n      <td>-0.390469</td>\n      <td>-0.21146</td>\n      <td>-0.016692</td>\n      <td>-0.075285</td>\n      <td>0.987546</td>\n      <td>-2.920398e-01</td>\n      <td>0.270313</td>\n      <td>0.599925</td>\n    </tr>\n    <tr>\n      <th>474</th>\n      <td>-0.121686</td>\n      <td>-0.044151</td>\n      <td>-0.09398</td>\n      <td>-0.198579</td>\n      <td>-0.137224</td>\n      <td>-0.311638</td>\n      <td>-0.208937</td>\n      <td>-0.259803</td>\n      <td>-0.240027</td>\n      <td>-0.157877</td>\n      <td>...</td>\n      <td>1.403958</td>\n      <td>-0.137224</td>\n      <td>-0.390469</td>\n      <td>-0.21146</td>\n      <td>-0.022439</td>\n      <td>0.672959</td>\n      <td>0.852400</td>\n      <td>5.364665e-01</td>\n      <td>0.270313</td>\n      <td>1.727420</td>\n    </tr>\n    <tr>\n      <th>1303</th>\n      <td>-0.121686</td>\n      <td>-0.044151</td>\n      <td>-0.09398</td>\n      <td>5.035769</td>\n      <td>-0.137224</td>\n      <td>-0.311638</td>\n      <td>-0.208937</td>\n      <td>-0.259803</td>\n      <td>-0.240027</td>\n      <td>-0.157877</td>\n      <td>...</td>\n      <td>-0.712272</td>\n      <td>-0.137224</td>\n      <td>2.561020</td>\n      <td>-0.21146</td>\n      <td>-0.478704</td>\n      <td>-0.075285</td>\n      <td>-1.005856</td>\n      <td>-7.997526e-01</td>\n      <td>0.270313</td>\n      <td>-0.572506</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 45 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyreal.transformers import OneHotEncoder, MultiTypeImputer, StandardScaler, fit_transformers\n",
    "\n",
    "oh_encoder = OneHotEncoder(columns=[\"Neighborhood\", \"Material\"], handle_unknown=\"ignore\")\n",
    "imputer = MultiTypeImputer()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "transformers = [oh_encoder, imputer, scaler]\n",
    "fit_transformers(transformers, x_train).head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-19T21:29:19.642618Z",
     "start_time": "2024-07-19T21:29:19.581612Z"
    }
   },
   "id": "da666fc9d0b86df6",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelling\n",
    "\n",
    "We can now transform our training and testing data, and initialize, train, and evaluate our ML model.\n",
    "\n",
    "In this guide, we will use LightGBM, a powerful and lightweight library that offers classfiers and regressors using the gradient boosting framework. \n",
    "It is an effective choice for many ML use cases."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6249bff7ce879d4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 946\n",
      "[LightGBM] [Info] Number of data points in the train set: 1028, number of used features: 31\n",
      "[LightGBM] [Info] Start training from score 180253.797665\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.8008784525798829"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyreal.transformers import run_transformers\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "x_train_model = run_transformers(transformers, x_train)\n",
    "x_test_model = run_transformers(transformers, x_test)\n",
    "\n",
    "model = LGBMRegressor().fit(x_train_model, y_train)\n",
    "\n",
    "model.score(x_test_model, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-19T21:29:20.055428Z",
     "start_time": "2024-07-19T21:29:19.645619Z"
    }
   },
   "id": "834ff0a3692c0d27",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating New Applications (RealApps)\n",
    "\n",
    "We can now combine the components we have created to create a new application, using the RealApp object. \n",
    "We set the ID column to \"House ID\", which is the column we use to ID our input data. We also pass in\n",
    "a feature description dictionary, which converts our column names to more useful descriptions. Finally, \n",
    "we set a pred format functions to format the model predictions to dollar amounts."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65015526ebf2b06e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pyreal import RealApp\n",
    "\n",
    "feature_descriptions = {'LotArea': 'Lot size in square feet', \n",
    "                        'Neighborhood': 'Neighborhood', \n",
    "                        'OverallQuality': 'Overall quality of the house finishing and materials (1-10)', \n",
    "                        'YearBuilt': 'Original construction date', \n",
    "                        'Material': 'Exterior material of house', \n",
    "                        'BasementSize': 'Total basement area in square feet', \n",
    "                        'CentralAir': 'Central air conditioning', \n",
    "                        'HouseSize': 'Total above ground living area in square feet'}\n",
    "\n",
    "realapp = RealApp(model, \n",
    "                  X_train_orig=x_train, \n",
    "                  y_train=y_train, \n",
    "                  transformers=transformers,\n",
    "                  id_column=\"House ID\",\n",
    "                  feature_descriptions=feature_descriptions,\n",
    "                  pred_format_func=lambda x: f\"${x:,.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-19T21:29:20.071435Z",
     "start_time": "2024-07-19T21:29:20.056429Z"
    }
   },
   "id": "d0d2aed2a921365",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  Using Applications (RealApps)\n",
    "\n",
    "Having created your RealApp, you can now use it to make predictions with and understand your ML model.\n",
    "\n",
    "## Predictions\n",
    "The most basic yet important functionality of an ML model is making predictions. For this, you can use the .predict() function. This function takes data in the original format, and then runs all transformers needed to prepare your input data for the model.\n",
    "\n",
    "The output of the predict function is a dictionary with keys determined by the ID column. If not ID column is provided, the output is indexed by input index (row names).\n",
    "This allows you to access predictions for specific instances by ID."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ec190e53e47429f"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted price for House 101: $132,924.72\n"
     ]
    }
   ],
   "source": [
    "predictions = realapp.predict(x_input)\n",
    "\n",
    "print(f\"Predicted price for House 101: {predictions['House 101']}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-19T21:29:20.117948Z",
     "start_time": "2024-07-19T21:29:20.072434Z"
    }
   },
   "id": "ff77d6baf87bc246",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Explanations\n",
    "Sometimes you may want more information about how an ML model came up with its prediction on an input. Or, you may have questions about the ML model in general.\n",
    "\n",
    "For our example application of predicting house prices based on information about houses, you may have questions like:\n",
    "1. What information about the house (or features) contributed to the prediction of $137,000?\n",
    "2. Have we seen houses in the past similar to this one, and what were their prices?\n",
    "3. What features, in general, does the model consider most important for predicting house prices?\n",
    "4. How does the model use the \"house size\" feature? Are bigger houses always predicted to be more expensive?\n",
    "\n",
    "### What features contributed to the model prediction?\n",
    "To get a list of how much each feature in your input data contributed to the model's prediction, you can use the `.produce_feature_contributions(x_orig)` function.\n",
    "\n",
    "Feature contribution outputs from RealApps are indexed by row ids, found in the column labelled by the optional id_column parameter to RealApps, or by the index (row labels) of the input data if no id column is provided. \n",
    "This allows us to access the explanation for a given house by ID:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74d62f1687c832b0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Lot size in square feet', 'Overall quality of the house finishing and materials (1-10)', 'Original construction date', 'Total basement area in square feet', 'Central air conditioning', 'Total above ground living area in square feet', 'Exterior material of house'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m contribution_scores \u001B[38;5;241m=\u001B[39m \u001B[43mrealapp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mproduce_feature_contributions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_input\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude_average_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m contribution_scores[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHouse 101\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\Documents\\github\\pyreal\\pyreal\\realapp\\realapp.py:734\u001B[0m, in \u001B[0;36mRealApp.produce_feature_contributions\u001B[1;34m(self, x_orig, model_id, x_train_orig, y_train, algorithm, format_output, shap_type, force_refit, training_size, num_features, select_by, include_average_values)\u001B[0m\n\u001B[0;32m    731\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m algorithm \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    732\u001B[0m     algorithm \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshap\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 734\u001B[0m exp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_produce_explanation_helper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    735\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlfc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    736\u001B[0m \u001B[43m    \u001B[49m\u001B[43malgorithm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    737\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprepare_feature_contributions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    738\u001B[0m \u001B[43m    \u001B[49m\u001B[43mformat_feature_contribution_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    739\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx_train_orig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_train_orig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    740\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    741\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx_orig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_orig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    742\u001B[0m \u001B[43m    \u001B[49m\u001B[43mformat_output\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mformat_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    743\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    744\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_refit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_refit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    745\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    746\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprepare_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshap_type\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mshap_type\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    747\u001B[0m \u001B[43m    \u001B[49m\u001B[43mformat_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minclude_average_values\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude_average_values\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    748\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    749\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_features \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[0;32m    751\u001B[0m         row_id: get_top_contributors(\n\u001B[0;32m    752\u001B[0m             exp[row_id], num_features\u001B[38;5;241m=\u001B[39mnum_features, select_by\u001B[38;5;241m=\u001B[39mselect_by\n\u001B[0;32m    753\u001B[0m         )\n\u001B[0;32m    754\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m row_id \u001B[38;5;129;01min\u001B[39;00m exp\n\u001B[0;32m    755\u001B[0m     }\n",
      "File \u001B[1;32m~\\Documents\\github\\pyreal\\pyreal\\realapp\\realapp.py:485\u001B[0m, in \u001B[0;36mRealApp._produce_explanation_helper\u001B[1;34m(self, explanation_type_code, algorithm, prepare_explainer_func, format_output_func, format_output, x_train_orig, y_train, x_orig, model_id, force_refit, training_size, prepare_kwargs, produce_kwargs, format_kwargs, narrative)\u001B[0m\n\u001B[0;32m    478\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m format_narratives(\n\u001B[0;32m    479\u001B[0m                 explanation\u001B[38;5;241m.\u001B[39mget(),\n\u001B[0;32m    480\u001B[0m                 ids\u001B[38;5;241m=\u001B[39mids,\n\u001B[0;32m    481\u001B[0m                 series\u001B[38;5;241m=\u001B[39mseries,\n\u001B[0;32m    482\u001B[0m                 optimized\u001B[38;5;241m=\u001B[39m\u001B[38;5;129;01mnot\u001B[39;00m format_output,\n\u001B[0;32m    483\u001B[0m             )\n\u001B[0;32m    484\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 485\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m format_output_func(\n\u001B[0;32m    486\u001B[0m                 explanation,\n\u001B[0;32m    487\u001B[0m                 ids,\n\u001B[0;32m    488\u001B[0m                 optimized\u001B[38;5;241m=\u001B[39m\u001B[38;5;129;01mnot\u001B[39;00m format_output,\n\u001B[0;32m    489\u001B[0m                 series\u001B[38;5;241m=\u001B[39mseries,\n\u001B[0;32m    490\u001B[0m                 \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mformat_kwargs\n\u001B[0;32m    491\u001B[0m             )\n\u001B[0;32m    492\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    493\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m narrative:\n",
      "File \u001B[1;32m~\\Documents\\github\\pyreal\\pyreal\\realapp\\realapp.py:58\u001B[0m, in \u001B[0;36mformat_feature_contribution_output\u001B[1;34m(explanation, ids, series, optimized, include_average_values)\u001B[0m\n\u001B[0;32m     53\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m explanation\u001B[38;5;241m.\u001B[39mget_average_values() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m     55\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRequested average values to be included in explanation, but explainer did not\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     56\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m provide them\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     57\u001B[0m         )\n\u001B[1;32m---> 58\u001B[0m     average_mode \u001B[38;5;241m=\u001B[39m \u001B[43mexplanation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_average_values\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcontributions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     59\u001B[0m     explanation_dict[row_id] \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame\u001B[38;5;241m.\u001B[39mfrom_dict(\n\u001B[0;32m     60\u001B[0m         {\n\u001B[0;32m     61\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFeature Name\u001B[39m\u001B[38;5;124m\"\u001B[39m: feature_names\u001B[38;5;241m.\u001B[39mvalues,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     65\u001B[0m         }\n\u001B[0;32m     66\u001B[0m     )\n\u001B[0;32m     67\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pyreal-AeQwnMfy-py3.10\\lib\\site-packages\\pandas\\core\\series.py:1033\u001B[0m, in \u001B[0;36mSeries.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1030\u001B[0m     key \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(key, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mbool\u001B[39m)\n\u001B[0;32m   1031\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_values(key)\n\u001B[1;32m-> 1033\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_with\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pyreal-AeQwnMfy-py3.10\\lib\\site-packages\\pandas\\core\\series.py:1073\u001B[0m, in \u001B[0;36mSeries._get_with\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1070\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miloc[key]\n\u001B[0;32m   1072\u001B[0m \u001B[38;5;66;03m# handle the dup indexing case GH#4246\u001B[39;00m\n\u001B[1;32m-> 1073\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pyreal-AeQwnMfy-py3.10\\lib\\site-packages\\pandas\\core\\indexing.py:1103\u001B[0m, in \u001B[0;36m_LocationIndexer.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1100\u001B[0m axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxis \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m   1102\u001B[0m maybe_callable \u001B[38;5;241m=\u001B[39m com\u001B[38;5;241m.\u001B[39mapply_if_callable(key, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj)\n\u001B[1;32m-> 1103\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmaybe_callable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pyreal-AeQwnMfy-py3.10\\lib\\site-packages\\pandas\\core\\indexing.py:1332\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_axis\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1329\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(key, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mndim\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m key\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1330\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot index with multidimensional key\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1332\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_iterable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1334\u001B[0m \u001B[38;5;66;03m# nested tuple slicing\u001B[39;00m\n\u001B[0;32m   1335\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_nested_tuple(key, labels):\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pyreal-AeQwnMfy-py3.10\\lib\\site-packages\\pandas\\core\\indexing.py:1272\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_iterable\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1269\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_key(key, axis)\n\u001B[0;32m   1271\u001B[0m \u001B[38;5;66;03m# A collection of keys\u001B[39;00m\n\u001B[1;32m-> 1272\u001B[0m keyarr, indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_listlike_indexer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1273\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_reindex_with_indexers(\n\u001B[0;32m   1274\u001B[0m     {axis: [keyarr, indexer]}, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, allow_dups\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1275\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pyreal-AeQwnMfy-py3.10\\lib\\site-packages\\pandas\\core\\indexing.py:1462\u001B[0m, in \u001B[0;36m_LocIndexer._get_listlike_indexer\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1459\u001B[0m ax \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_axis(axis)\n\u001B[0;32m   1460\u001B[0m axis_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_axis_name(axis)\n\u001B[1;32m-> 1462\u001B[0m keyarr, indexer \u001B[38;5;241m=\u001B[39m \u001B[43max\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1464\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m keyarr, indexer\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pyreal-AeQwnMfy-py3.10\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5877\u001B[0m, in \u001B[0;36mIndex._get_indexer_strict\u001B[1;34m(self, key, axis_name)\u001B[0m\n\u001B[0;32m   5874\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   5875\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[1;32m-> 5877\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   5879\u001B[0m keyarr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[0;32m   5880\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[0;32m   5881\u001B[0m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pyreal-AeQwnMfy-py3.10\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5941\u001B[0m, in \u001B[0;36mIndex._raise_if_missing\u001B[1;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[0;32m   5938\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   5940\u001B[0m not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n\u001B[1;32m-> 5941\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyError\u001B[0m: \"['Lot size in square feet', 'Overall quality of the house finishing and materials (1-10)', 'Original construction date', 'Total basement area in square feet', 'Central air conditioning', 'Total above ground living area in square feet', 'Exterior material of house'] not in index\""
     ]
    }
   ],
   "source": [
    "contribution_scores = realapp.produce_feature_contributions(x_input, include_average_values=True)\n",
    "contribution_scores[\"House 101\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-19T21:29:21.719360Z",
     "start_time": "2024-07-19T21:29:20.119948Z"
    }
   },
   "id": "ae411592de8367a7",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you are only interested in the most contributing features (either positively, negatively, or by absolute value), you can using the num_features and select_by parameters. Alternatively, you can extract the top contributing features from an already-generated explanation using the get_top_contributors function."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c299a95b4b3fc3b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pyreal.utils import get_top_contributors\n",
    "\n",
    "# select_by is one of: \"absolute\", \"min\", \"max\"\n",
    "top_contributions_for_house_101 = get_top_contributors(contribution_scores[\"House 101\"], \n",
    "                                                       num_features=5, \n",
    "                                                       select_by=\"absolute\")\n",
    "\n",
    "# Or...\n",
    "top_5_contribution_scores = realapp.produce_feature_contributions(x_input, \n",
    "                                                                  num_features=5,\n",
    "                                                                  select_by=\"absolute\")\n",
    "top_5_contribution_scores[\"House 101\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-19T21:29:21.721361Z"
    }
   },
   "id": "45ea8ef9556137b0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Which past cases are similar to this one?\n",
    "You can get a list of past cases (rows of data in the training data) that are similar to your input data, as well as the ground-truth target (y) value for those cases, by using the produce_similiar_examples function:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "830610cdf2997bc9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get the three most similar houses from the \n",
    "# training dataset to each house in houses\n",
    "similar_houses = realapp.produce_similar_examples(x_input, \n",
    "                                                  num_examples=3)\n",
    "\n",
    "display(similar_houses[\"House 101\"][\"X\"])\n",
    "display(similar_houses[\"House 101\"][\"y\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-19T21:29:21.722362Z",
     "start_time": "2024-07-19T21:29:21.721361Z"
    }
   },
   "id": "c98cca91d2c046b3",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### What features does the model consider most important in general?\n",
    "\n",
    "You may be interested in understanding which features the model considers most important in general, without considering a specific input. For this, you can use the produce_feature_importance function, which takes no required inputs:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "924a4ecf91c5d85e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "importance_scores = realapp.produce_feature_importance()\n",
    "\n",
    "# Like with feature contributions, you can return only the most important features\n",
    "#  or extract the most important features using `get_top_contributors`\n",
    "top_5_importance_scores = realapp.produce_feature_importance(num_features=5)\n",
    "top_5_importance_scores"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c00bcdfd7994e6a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### How does the model use a specific feature?\n",
    "To understand how the model uses a specific feature, you can generate feature contributions for the full training dataset, and then investigate how the contributions vary for a specific feature by value.\n",
    "To save time generating large numbers of contributions, and get the output in a more usable format for this specific use-case, you can set the format_output parameter to produce functions to False."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2590968b89c557d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "contribution_scores_df = realapp.produce_feature_contributions(x_input, format_output=False)\n",
    "\n",
    "# explanation is now a tuple of (feature contributions, feature values), where\n",
    "#  the column names are feature descriptions and the index are the row ids.\n",
    "\n",
    "contributions, values = contribution_scores_df\n",
    "\n",
    "# You can now investigate a single features contributions with:\n",
    "pd.DataFrame({\"Value of lot size feature\": values[\"Lot size in square feet\"], \n",
    "              \"Contribution of lot size feature\": contributions[\"Lot size in square feet\"]})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-19T21:29:21.723360Z"
    }
   },
   "id": "fe41f580cc714ef8",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualization\n",
    "Pyreal's visualize module includes several functions that take in RealApp output directly to generate explanation plots.\n",
    "\n",
    "The feature bar plot can visualize general feature importance or feature contributions for a single input."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff345510571d4f27"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pyreal.visualize import feature_bar_plot\n",
    "\n",
    "feature_bar_plot(importance_scores)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9cc31bf48201eefb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "For feature contribution explanations, the feature value is included in parentheses in the x-axis labels."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7d6a5b3169e1744"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "feature_bar_plot(contribution_scores[\"House 101\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-19T21:29:21.728362Z",
     "start_time": "2024-07-19T21:29:21.728362Z"
    }
   },
   "id": "53cb5c94eef3b2c2",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Strip plots are an effective way to visualize feature contributions for multiple inputs at a time, to understand the general trends of how the ML model uses features."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdd38e0b2a32c652"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pyreal.visualize import strip_plot\n",
    "\n",
    "training_set_contributions = realapp.produce_feature_contributions(x_train.iloc[:100])\n",
    "strip_plot(training_set_contributions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-19T21:29:21.731366Z",
     "start_time": "2024-07-19T21:29:21.730365Z"
    }
   },
   "id": "eeee875735e6847f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Scatter plots allow you to investigate how the model uses a specific feature, across the full range of that feature's values:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "718c0b34d728e13"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pyreal.visualize import feature_scatter_plot\n",
    "\n",
    "# Optionally pass in predictions to color the plot by prediction\n",
    "predictions = realapp.predict(x_train.iloc[:100], format=False)\n",
    "\n",
    "feature_scatter_plot(training_set_contributions, \"Total above ground living area in square feet\", predictions=predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-19T21:29:21.733362Z",
     "start_time": "2024-07-19T21:29:21.732362Z"
    }
   },
   "id": "4ee0934993904b5c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "To get a clean table comparing the feature values of an input data row to those of similar examples, you can use the example_table function:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41b514af927a378f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pyreal.visualize import example_table\n",
    "\n",
    "example_table(similar_houses[\"House 101\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-19T21:29:21.735361Z"
    }
   },
   "id": "53564fdf7431760c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Narrative Explanations (Using LLMs)\n",
    "You may prefer to get explanations in natural-language sentences. For example, instead of a table or graph of feature contributions, you may prefer what we call a *narrative explanation*.\n",
    "\n",
    "To generate narrative explanations accurately, we plug the explanations generated by Pyreal into a large language model (LLM), which automatically converts it into sentence format.\n",
    "Currently, Pyreal requires an OpenAI API key to use its narrative explanation functionality, which will incur a cost. \n",
    "To generate narrative explanations, you can either pass your API key to the RealApp object at initialization or with the `set_openai_client` function, or to the produce function. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b30904648094371d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# You can create your own keys.yml file with the line `openai_api_key: [your key]`\n",
    "#   or manually set openai_api_key below\n",
    "with open(\"keys.yml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    openai_api_key = config[\"openai_api_key\"]\n",
    "\n",
    "realapp.set_openai_client(openai_api_key=openai_api_key)\n",
    "narratives = realapp.produce_narrative_feature_contributions(x_input)\n",
    "\n",
    "narratives[\"House 101\"]"
   ],
   "metadata": {
    "collapsed": false,
    "tags": [
     "raises-exception"
    ],
    "ExecuteTime": {
     "end_time": "2024-07-19T21:29:21.736361Z",
     "start_time": "2024-07-19T21:29:21.736361Z"
    }
   },
   "id": "40dc5d39dbdcff59",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can train the LLM on what kinds of explanations you want. This is called few-shot learning. The LLM asks you for some examples of explanations, and then learns from those examples.\n",
    "To run this training, you can use the .train_feature_contribution_llm. This function will show a few feature contributions explanations, and ask you for narrative versions using Python input/output."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed84637a814476cd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set to True to run this cell\n",
    "RUN_TRAINING = False\n",
    "\n",
    "if RUN_TRAINING:\n",
    "    realapp.train_feature_contribution_llm(num_inputs=2, num_features=2)\n",
    "    narratives = realapp.produce_narrative_feature_contributions(x_input)\n",
    "    \n",
    "    # Explanations will now more closely match the examples you provided\n",
    "    display(narratives[\"House 101\"])"
   ],
   "metadata": {
    "collapsed": false,
    "tags": [
     "raises-exception"
    ],
    "ExecuteTime": {
     "start_time": "2024-07-19T21:29:21.739363Z"
    }
   },
   "id": "87ceb32bae574284",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
