{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will use Pyreal to find the top contributing features in the Student Performance dataset.\n",
    "\n",
    "Data source:\n",
    "\n",
    "P. Cortez and A. Silva. Using Data Mining to Predict Secondary School Student Performance. In A. Brito and J. Teixeira Eds., Proceedings of 5th FUture BUsiness TEChnology Conference (FUBUTEC 2008) pp. 5-12, Porto, Portugal, April, 2008, EUROSIS, ISBN 978-9077381-39-7.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load in the data, and provide human-readable descriptions of every feature. These descriptions will make the resulting explanations much more user friendly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_descriptions = {\n",
    "    \"school\":\"School\",\n",
    "    \"sex\":\"Sex\",\n",
    "    \"age\":\"Age\",\n",
    "    \"address\":\"Address type\",\n",
    "    \"famsize\":\"Family size\",\n",
    "    \"Pstatus\":\"Parent's cohibition status\",\n",
    "    \"Medu\":\"Mother's education\",\n",
    "    \"Fedu\":\"Father's education\",\n",
    "    \"Mjob\":\"Mother's job\",\n",
    "    \"Fjob\":\"Father's job\",\n",
    "    \"reason\":\"Reason for choosing this school\",\n",
    "    \"guardian\":\"Student's guardian\",\n",
    "    \"traveltime\":\"Home to school travel time\",\n",
    "    \"studytime\":\"Weekly study time\",\n",
    "    \"failures\":\"Number of past class failures\",\n",
    "    \"schoolsup\":\"Extra education support\",\n",
    "    \"famsup\":\"Family eductional support\",\n",
    "    \"paid\":\"Extra paid classes within the subject\",\n",
    "    \"activities\":\"Extra-curricular activities\",\n",
    "    \"nursery\":\"Attended nursery school\",\n",
    "    \"higher\":\"Wants to take higher education\",\n",
    "    \"internet\":\"Has internet at home\",\n",
    "    \"romantic\":\"In a romantic relationship\",\n",
    "    \"famrel\":\"Quality of family relationships (1-5)\",\n",
    "    \"freetime\":\"Amount of free time after school (1-5)\",\n",
    "    \"goout\":\"Frequency of going out with friends (1-5)\",\n",
    "    \"Dalc\":\"Frequency of workday alcohol consumption (1-5)\",\n",
    "    \"Walc\":\"Frequency of workday alcohol consumption (1-5)\",\n",
    "    \"health\":\"Current health status (1-5)\",\n",
    "    \"absences\":\"Number of school absences\"\n",
    "}\n",
    "\n",
    "file_path = \"student-por.csv\"\n",
    "data_table = pd.read_csv(file_path, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we extract our chosen target variable. In this case, we will be predicting whether a student will pass (score > 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (data_table[\"G3\"]>10).astype(int)\n",
    "\n",
    "data = data_table.drop([\"G1\", \"G2\",\"G3\"], axis='columns')\n",
    "X = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create the transformers. The first will encode boolean features as integers, the second will one hot encode categorical features, and the first with standardize the data.\n",
    "\n",
    "Some transformation and explanation type combos require post-hoc transformations on the explanations themselves. In this case, we will run SHAP on the one-hot-encoded features, and then recombine the contributions of these features. The OneHotEncoderWrapper includes this functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyreal.transformers import OneHotEncoder, DataFrameWrapper\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class BooleanEncoder:\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "    def transform(self, data):\n",
    "        data_transform = data.copy()\n",
    "        for col in self.cols:\n",
    "            data_transform[col].replace(('yes', 'no'), (1, 0), inplace=True)\n",
    "        data_transform[\"famsize\"] = data_transform[\"famsize\"].astype('category')\n",
    "        data_transform[\"famsize\"].cat.set_categories(['LE3', 'GT3'], inplace=True)\n",
    "        data_transform[\"famsize\"].cat.reorder_categories(['LE3', 'GT3'], inplace=True)\n",
    "        data_transform[\"famsize\"] = data_transform[\"famsize\"].cat.codes\n",
    "        return data_transform\n",
    "\n",
    "onehotencoder = OneHotEncoder([\"school\", \"sex\", \"address\", \"Pstatus\", \"reason\", \"guardian\", \"Mjob\", \"Fjob\"])\n",
    "onehotencoder.fit(data)\n",
    "\n",
    "boolean_encoder = BooleanEncoder([\"schoolsup\", \"famsup\", \"paid\", \"activities\", \"nursery\", \"internet\", \"romantic\", \"higher\"])\n",
    "\n",
    "standard_scaler = DataFrameWrapper(StandardScaler())\n",
    "data_for_fitting = boolean_encoder.transform(onehotencoder.transform(X))\n",
    "standard_scaler.fit(data_for_fitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can create the LocalFeatureContribution object, using the information generated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyreal.explainers import LocalFeatureContribution\n",
    "\n",
    "m_transforms = [onehotencoder, boolean_encoder, standard_scaler]\n",
    "lfc = LocalFeatureContribution(model=\"model.pkl\",\n",
    "                               x_train_orig=X, e_transforms=m_transforms,\n",
    "                               m_transforms=m_transforms,\n",
    "                               feature_descriptions=feature_descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lfc.model_predict(X)\n",
    "print(\"Accuracy: %.2f%%\" % (np.mean(preds==y)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we fit our explainer, and take a look at the most predictive features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfc.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyreal.utils import visualize\n",
    "\n",
    "input_to_explain = X.iloc[0]\n",
    "contributions = lfc.produce(input_to_explain)\n",
    "x_interpret = lfc.convert_data_to_interpretable(input_to_explain)\n",
    "\n",
    "visualize.plot_top_contributors(contributions, select_by=\"absolute\", values=x_interpret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also generate a global feature importance explanation, that summarizes the overall importance of features across all inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyreal.explainers import GlobalFeatureImportance\n",
    "\n",
    "gfi = GlobalFeatureImportance(model=\"model.pkl\",\n",
    "                              x_train_orig=X, e_transforms=m_transforms,\n",
    "                              m_transforms=m_transforms,\n",
    "                              feature_descriptions=feature_descriptions,\n",
    "                              fit_on_init=True)\n",
    "\n",
    "importances = gfi.produce(input_to_explain)\n",
    "visualize.plot_top_contributors(importances, select_by=\"absolute\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}